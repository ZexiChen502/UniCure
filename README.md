# UniCure: A Multi-Modal Model for Predicting Personalized Cancer Therapy Response üíä

## Overview üåü
**UniCure is a multi-modal model integrating omics (UCE) and chemical (Uni-mol) foundation models to predict transcriptomic drug responses across diverse cellular contexts.**

üí° **Key Innovations**  
- **FlexPert**: Sliding-window cross-attention for flexible drug-cell interaction modeling  
- **LoRA-PEFT**: Parameter-efficient tuning preserving pretrained knowledge  
- **MMD loss**: Handles unpaired perturbation data without cell matching    
- **Staged training**: Enhancing computational efficiency and functional modularity

## System Requirements üõ†

### Hardware Requirements
| Use Case              | Minimum Configuration                | Recommended Configuration       |
|-----------------------|--------------------------------------|---------------------------------|
| **Full Reproduction** | 4√ó NVIDIA GPUs (80GB VRAM each) | 8√ó A100/H100 80GB |
| **Testing/Inference** | 1√ó NVIDIA GPU (32GB+ VRAM) | 1√ó NVIDIA GPU (80GB VRAM) |

### Software Requirements
**OS:** Linux (Ubuntu 22.04 LTS or Rocky Linux 8.6+ recommended)  
**Environment Manager:** Miniconda/Mamba  

#### Installation via Conda:
```
# Base environment (minimal)
conda env create -f environment.yml

# Full environment (with development tools)
conda env create -f environment_full.yml
```

#### Manual Installation Steps (Recommended):
```
1. Install Python 3.10
conda create -n unicure python=3.10
conda activate unicure

2. Install PyTorch (select appropriate CUDA version)
‚ö† Check latest at: https://pytorch.org/get-started/locally/
pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

3. Install Accelerate & DeepSpeed (recommended for reproduction)
pip install accelerate
‚ö† Follow configuration (about how to configure DeepSpeed): https://github.com/huggingface/accelerate

4. Install core dependencies
pip install numpy pandas scikit-learn fastparquet tqdm anndata scanpy lora-pytorch

5. Install Uni-Mol (required for testing)
You can create a new conda environment. 
https://github.com/deepmodeling/Uni-Mol
```

## Datasets Requirements üìö

### Step 1: Download Core Folders
Download and **overwrite** these folders to your local UniCure directories:

1. **[data folder](https://drive.google.com/drive/folders/1VPXl8h8iuhr8IdrAmAWQ9ldEHkWRCGWq?usp=drive_link)**  
   - Contains: LINCS and SciPlex datasets
   - Local path: `your_project_path/UniCure/data/`

2. **[requirement folder](https://drive.google.com/drive/folders/1VPXl8h8iuhr8IdrAmAWQ9ldEHkWRCGWq?usp=drive_link)**  
   - Contains: configuration files
   - Local path: `your_project_path/UniCure/requirement/`

3. **[model weights](https://drive.google.com/drive/folders/1qZ4QwEXST_FcIZDTizMu7aH-OXpdc_CB?usp=drive_link)**  
   - Contains: Pre-trained model weights & Dataset splits (Training, Validation, and Test sets)
   - Local path: `your_project_path/UniCure/result/`
   
> ‚ö†Ô∏è **Overwrite Notice**: Replace existing directories completely when copying <br> ‚ö†Ô∏è **Unzip Notice**: Unzip Unicure_best_model.rar

### Step 2: Download UCE Pretraining Files
Download these essential files to `requirement/UCE_pretraining_files/`:

| File | Size | Required Path |
|------|------|---------------|
| **[33l_8ep_1024t_1280.torch](https://figshare.com/articles/dataset/Universal_Cell_Embedding_Model_Files/24320806?file=43423236)** | 4.2 GB | `requirement/UCE_pretraining_files/` |
| **[all_tokens.torch](https://figshare.com/articles/dataset/Universal_Cell_Embedding_Model_Files/24320806?file=43423236)** | 780 MB | `requirement/UCE_pretraining_files/` |
| **[species_chrom.csv](https://figshare.com/articles/dataset/Universal_Cell_Embedding_Model_Files/24320806?file=43423236)** | 12 KB | `requirement/UCE_pretraining_files/` |

### Verification Checklist
After downloading, confirm directory structure:
```
UniCure/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ lincs2020/
‚îÇ	‚îî‚îÄ‚îÄ sciplex/
‚îú‚îÄ‚îÄ result/
‚îÇ   ‚îî‚îÄ‚îÄ 11/
‚îÇ       ‚îú‚îÄ‚îÄ lincs2020/
‚îÇ       ‚îú‚îÄ‚îÄ sciplex3/ 
‚îÇ	    ‚îî‚îÄ‚îÄ sciplex4/
‚îî‚îÄ‚îÄ requirement/
    ‚îî‚îÄ‚îÄ UCE_pretraining_files/
	    ‚îú‚îÄ‚îÄ protein_embeddings/
        ‚îú‚îÄ‚îÄ 33l_8ep_1024t_1280.torch
        ‚îú‚îÄ‚îÄ all_tokens.torch
        ‚îî‚îÄ‚îÄ species_chrom.csv
```

## Quick Test :zap:
```
python quick_pred.py
```

## Reproduction :fire:

Our training pipeline is designed to be progressive. Later stages depend on the pre-trained weights generated by the previous stages (e.g., LINCS Step 1 -> LINCS Step 2 -> Sciplex 3 -> Sciplex 4). 

You can choose to run the entire pipeline at once or execute each stage individually.

### Option 1: Run the Entire Pipeline
To sequentially train and test all stages (LINCS Step 1 & 2, Sciplex 3, and Sciplex 4) with the default seed (`11`), simply run:

```bash
python main.py --run_all
```

### Option 2: Run Step-by-Step (Recommended)
If you want to train a specific stage or debug, you can run the stages individually using the provided flags. 

**1. LINCS Stage 1:**
```bash
python main.py --run_lincs1
```

**2. LINCS Stage 2 (Train & Test):**
*(Note: Ensure Stage 1 is completed and Cell Embedding is generated by `generate_emb.py` before running this)*
```bash
python main.py --run_lincs2
```

**3. Sciplex 3 (Train & Test):**
```bash
python main.py --run_sciplex3
```

**4. Sciplex 4 (Train & Test):**
```bash
python main.py --run_sciplex4
```

### Advanced: Customizing the Random Seed
By default, the pipeline uses `seed=11`. You can easily change the random seed for any execution by adding the `--seed` argument. For example, to run the Sciplex 3 stage with seed `42`:

```bash
python main.py --run_sciplex3 --seed 42
```

## Cell Embedding Generation (After Stage 1 Training) :fire:
```
python generate_emb.py
```

## Contact üì¨
Zexi Chen
üìß Email: jersey8768@outlook.com

## Citation üß∑
doi: https://doi.org/10.1101/2025.06.14.658531


## License üìÑ
This project is licensed under the Apache License 2.0 - see the [LICENSE](LICENSE) file for details.


